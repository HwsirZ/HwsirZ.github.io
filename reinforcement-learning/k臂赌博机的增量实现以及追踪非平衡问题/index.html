<!doctype html><html lang=en-US data-theme=dark><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.147.9"><link rel="shortcut icon" type=image/x-icon href><link rel=icon type=image/x-icon href><link rel=icon type=image/png sizes=16x16 href><link rel=icon type=image/png sizes=32x32 href><link rel=apple-touch-icon sizes=180x180 href><meta itemprop=name content="K臂赌博机的增量实现以及追踪非平衡问题"><meta itemprop=description content="Keep it simple, keep it powerful."><meta name=description content="Keep it simple, keep it powerful."><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="https://hwsirz.github.io/images/profile.jpg"><meta itemprop=keywords content="Hugo,NexT,theme,simple,powerful"><meta property="og:type" content="article"><meta property="og:title" content="K臂赌博机的增量实现以及追踪非平衡问题"><meta property="og:description" content="Keep it simple, keep it powerful."><meta property="og:image" content="/images/profile.jpg"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="https://hwsirz.github.io/reinforcement-learning/k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/"><meta property="og:site_name" content="惜日短"><meta property="og:locale" content="en-US"><meta property="article:author" content="惜日短"><meta property="article:published_time" content="2025-09-20 22:04:16 +0800 CST"><meta property="article:modified_time" content="2025-09-20 22:04:16 +0800 CST"><link type=text/css rel=stylesheet href=https://hwsirz.github.io/js/3rd/font-awesome/6.7.2/css/all.min.css><link type=text/css rel=stylesheet href=https://hwsirz.github.io/js/3rd/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://hwsirz.github.io/js/3rd/viewerjs/1.11.6/viewer.min.css><link rel=stylesheet href="/css/main.min.css?=1761104601"><style type=text/css>.post-footer hr:after{content:"~ End Line ~"}.flinks-list-footer hr:after{content:"~ End Line ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return 0[0];const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),0[0]):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>K臂赌博机的增量实现以及追踪非平衡问题 - 惜日短</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>惜日短</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Build for Hugo Theme</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/home/main/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>Home</a></li><li class="menu-item menu-item-post"><a href=/post/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>post</a></li><li class="menu-item menu-item-Notes"><a href=/ class="menus-parent hvr-icon-pulse" rel=section><i class="fa fa-user hvr-icon"></i>Notes
<span class=menu-item-shrink-icon><i class="fa fa-angle-right"></i></span></a><ul class=menu-children><li class=menu-child-item><a href=/reinforcement-learning/ class=hvr-icon-pulse rel=section><i class="fa hvr-icon"></i>Reinforcement-Learning</a></li><li class=menu-child-item><a href=/visual-detection-model/ class=hvr-icon-pulse rel=section><i class="fa hvr-icon"></i>visual-detection-model</a></li><li class=menu-child-item><a href=/embodied-intelligence/ class=hvr-icon-pulse rel=section><i class="fa hvr-icon"></i>Embodied-Intelligence</a></li><li class=menu-child-item><a href=/linux/ class=hvr-icon-pulse rel=section><i class="fa hvr-icon"></i>Linux</a></li></ul></li><li class="menu-item menu-item-public"><a href=/publications/ class=hvr-icon-pulse rel=section><i class="fa fa-thumbs-up hvr-icon"></i>publications</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>Search</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=Searching... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>TOC</li><li class=sidebar-nav-overview>Overview</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#一增量实现以及非平稳问题>一：增量实现以及非平稳问题</a><ul><li><ul><li><a href=#alpha为常数时可以得到公式>$\alpha$为常数时，可以得到公式：</a></li><li><a href=#推导当--alpha_n--是任意序列时-q_n--的表达式>推导：当 $ \alpha_n $ 是任意序列时，$ Q_n $ 的表达式</a></li><li><a href=#推导收敛性>推导收敛性</a></li></ul></li></ul></li><li><a href=#二k臂赌博机的增量实现以及k臂赌博机非平稳问题的实验>二：K臂赌博机的增量实现以及K臂赌博机非平稳问题的实验</a><ul><li><a href=#关于k臂赌博机的非平稳性问题>关于k臂赌博机的非平稳性问题</a></li><li><a href=#结果>结果</a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=惜日短 src=/imgs/img-lazy-loading.gif data-src=/images/profile.jpg><p class=site-author-name itemprop=name>惜日短</p><div class=site-description itemprop=description>Keep it simple, keep it powerful.</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>1</span>
<span class=site-state-item-name>Posts</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>Categories</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>Tags</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/HwsirZ title="Github → https://github.com/HwsirZ" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>
Github
</a></span><span class=links-of-social-item><a href=wkt_cherish@qq.com title="QQ → wkt_cherish@qq.com" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-qq fa-fw hvr-icon"></i>
QQ</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en class=cc-opacity rel=noopener target=_blank title="Creative Commons"><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt="Creative Commons"></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
Links</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href title target=_blank></a></li><li class=links-of-blogroll-item><a href title target=_blank></a></li></ul></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title="Change Theme"><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title="Back to Top"><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><a role=button class="book-mark-link book-mark-link-fixed"></a><a href=https://github.com/hugo-next rel="noopener external nofollow noreferrer" target=_blank title="Follow me on GitHub" class="exturl github-corner"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentColor" class="octo-body"/></svg></a><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=https://hwsirz.github.io/reinforcement-learning/k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/images/profile.jpg"><meta itemprop=name content="惜日短"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="惜日短"><meta itemprop=description content="Keep it simple, keep it powerful."></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="K臂赌博机的增量实现以及追踪非平衡问题"><meta itemprop=description content="K臂赌博机的增量实现以及追踪非平衡问题"></span><header class=post-header><h1 class=post-title itemprop="name headline">K臂赌博机的增量实现以及追踪非平衡问题</h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="fas fa-solid fa-calendar"></i>
</span><span class=post-meta-item-text title="Publish on">Publish on:
</span><time title="Create Time:2025/09/20 22:04:16 +08:00" itemprop="dateCreated datePublished" datetime="2025-09-20 22:04:16 +0800 CST">2025/09/20</time></span></div><div class=post-meta-items><span class=post-meta-item title=Words><span class=post-meta-item-icon><i class="fas fa-solid fa-file-word"></i>
</span><span class=post-meta-item-text>Words:</span>
<span>2378</span></span></div></div></header><div class=post-body itemprop=articleBody>K臂赌博机的增量实现以及追踪非平衡问题
<a id=more></a><h2 id=一增量实现以及非平稳问题>一：增量实现以及非平稳问题
<a class=header-anchor href=#%e4%b8%80%e5%a2%9e%e9%87%8f%e5%ae%9e%e7%8e%b0%e4%bb%a5%e5%8f%8a%e9%9d%9e%e5%b9%b3%e7%a8%b3%e9%97%ae%e9%a2%98></a></h2><blockquote><p>所谓增量实现，就是对$Q_n$的计算方法，之前的计算是对过去所有奖励的一个平均值来估计奖励，而增量更新中，对于过去的奖励，有不同的权重，此时，$Q_n$的计算是过去所有奖励的权重和。</p></blockquote><p>首先是数学公式的推到，先推到对于之前求平均值的公式</p><p>$$
\begin{align}
Q_{n+1} & = \frac{R_1+R2+\dots +R_{n}}{n} \\
& = \frac{1}{n} \sum_{i=1}^{n} R_i \\
& = \frac{1}{n} (R_n + \sum_{i=1}^{n-1} R_{i}) \\
& = \frac{1}{n} (R_n + (n-1)\frac{1}{n-1}Q_n\sum_{i=1}^{n-1} R_{i}) \\
& = \frac{1}{n} (R_n + (n-1)Q_n) \\
& = Q_n + \frac{1}{n}(R_n - Q_n)
\end{align}
$$</p><p>将$\frac{1}{n}$替换为$\alpha, \quad \alpha \in (0,1] \quad$即表示增量更新的公式，用于非平稳问题的求解，此时的公式可以表示为：</p><p>$$
\begin{align}
Q_{n+1} & = Q_n + \alpha(R_n - Q_n) \\
& = \alpha R_n + (1-\alpha)Q_n \\
& = (1-\alpha)^{n}Q_1 + \sum_{i=1}^{n}\alpha (1 - \alpha )^{n-i}R_i
\end{align}
$$</p><p>权重之和$\quad (1-\alpha )^n + \sum_{i=1}^{n}\alpha(1-\alpha)^{n-i} = 1 \quad$ (使用等比数列的求和公式进行计算推导)，有时也称为<strong>指数新近加权平均值</strong>。</p><p>这里还有一个收敛性的推导：</p><p>$\sum_{n=1}^{\infty}\alpha_n(a) = \infty \text{ 以及 } \sum_{n=1}^{\infty}\alpha_n^{2}(a) &lt; \infty$</p><p>这个的计算也是对上述公式进行展开计算，看最后的Q值能否收敛到期望值，用到了一个叫做无穷级数收敛性的定理。</p><h4 id=alpha为常数时可以得到公式>$\alpha$为常数时，可以得到公式：
<a class=header-anchor href=#alpha%e4%b8%ba%e5%b8%b8%e6%95%b0%e6%97%b6%e5%8f%af%e4%bb%a5%e5%be%97%e5%88%b0%e5%85%ac%e5%bc%8f></a></h4><p>$$
Q_n = (1 - \alpha)^{n-1} Q_1 + \sum_{i=1}^{n-1} \alpha (1 - \alpha)^{n-1-i} R_i
$$</p><p>即：$ Q_n $ 是初始值 $ Q_1 $ 和历史奖励 $ R_1 $ 到 $ R_{n-1} $ 的<strong>指数加权平均</strong>。</p><h4 id=推导当--alpha_n--是任意序列时-q_n--的表达式>推导：当 $ \alpha_n $ 是任意序列时，$ Q_n $ 的表达式
<a class=header-anchor href=#%e6%8e%a8%e5%af%bc%e5%bd%93--alpha_n--%e6%98%af%e4%bb%bb%e6%84%8f%e5%ba%8f%e5%88%97%e6%97%b6-q_n--%e7%9a%84%e8%a1%a8%e8%be%be%e5%bc%8f></a></h4><p>$$
Q_n = \left( \prod_{k=1}^{n-1} (1 - \alpha_k) \right) Q_1 + \sum_{i=1}^{n-1} \left( \alpha_i \cdot \prod_{k=i+1}^{n-1} (1 - \alpha_k) \right) R_i
$$</p><p>在步长参数 $ \alpha_n $ 随时间变化的一般情况下，第 $ n $ 步的动作价值估计 $ Q_n $ 中：</p><blockquote><ul><li><p><strong>初始值 $ Q_1 $ 的权重</strong>为：</p><p>$$
w_0^{(n)} = \prod_{k=1}^{n-1} (1 - \alpha_k)
$$</p></li><li><p><strong>第 $ i $ 个奖励 $ R_i $（$ i = 1, 2, \dots, n-1 $）的权重</strong>为：</p><p>$$
w_i^{(n)} = \alpha_i \cdot \prod_{k=i+1}^{n-1} (1 - \alpha_k)
$$</p></li></ul><p>其中，<strong>如果乘积的下标上界小于下界（如 $ i+1 > n-1 $），则乘积定义为 1</strong>（空乘积）</p></blockquote><blockquote><p>对于一般步长序列 $ {\alpha_1, \alpha_2, \dots, \alpha_{n-1}} $，估计值 $ Q_n $ 可表示为：</p></blockquote><p>$$
Q_n = \underbrace{\left( \prod_{k=1}^{n-1} (1 - \alpha_k) \right)}_{\text{初始值权重}} Q_1 + \sum_{i=1}^{n-1} \underbrace{\left( \alpha_i \prod_{k=i+1}^{n-1} (1 - \alpha_k) \right)}_{\text{奖励 } R_i \text{ 的权重}} R_i
$$</p><h4 id=推导收敛性>推导收敛性
<a class=header-anchor href=#%e6%8e%a8%e5%af%bc%e6%94%b6%e6%95%9b%e6%80%a7></a></h4><p>先假设<strong>奖励无噪声</strong>，即每次 $ R_n = q^* $（确定性情形）</p><blockquote><p>$$
Q_{n+1} = Q_n + \alpha_n (q^* - Q_n) = (1 - \alpha_n) Q_n + \alpha_n q^*
$$</p></blockquote><blockquote><p>$$
Q_n = \left( \prod_{i=1}^{n-1} (1 - \alpha_i) \right) Q_1 + \left( 1 - \prod_{i=1}^{n-1} (1 - \alpha_i) \right) q^*
$$</p></blockquote><p>取极限 n → $\infty$</p><p>令：</p><blockquote><p>$$
C = \lim_{n \to \infty} \prod_{i=1}^{n-1} (1 - \alpha_i)
$$</p></blockquote><p>则：</p><blockquote><p>$$
\lim_{n \to \infty} Q_n = C \cdot Q_1 + (1 - C) \cdot q^*
$$</p></blockquote><p>分析 C 的值 —— 无穷乘积与无穷级数的关系</p><p>我们关心的是：</p><blockquote><p><strong>C 是否等于 0？</strong></p></blockquote><p>因为：</p><ul><li>若 $ C = 0 $ → $ Q_\infty = q^* $ ✅ 收敛到真实值；</li><li>若 $ C > 0 $ → $ Q_\infty = C Q_1 + (1 - C) q^* \ne q^* $（除非 $ Q_1 = q^* $）❌ 有初始偏差。</li></ul><p>数学定理（无穷乘积收敛性）</p><p>对序列 $ 0 &lt; \alpha_i &lt; 1 $，有：</p><blockquote><p>$$
\prod_{i=1}^\infty (1 - \alpha_i) > 0 \quad \text{当且仅当} \quad \sum_{i=1}^\infty \alpha_i &lt; \infty
$$</p></blockquote><p>换句话说：</p><blockquote><p>$$
\sum_{i=1}^\infty \alpha_i = \infty \quad \Longleftrightarrow \quad \prod_{i=1}^\infty (1 - \alpha_i) = 0
$$</p></blockquote><p>证明思路（取对数）：</p><p>令：</p><blockquote><p>$$
P_n = \prod_{i=1}^{n} (1 - \alpha_i)
\Rightarrow \ln P_n = \sum_{i=1}^{n} \ln(1 - \alpha_i)
$$</p></blockquote><p>利用近似：当 $ \alpha_i \to 0 $，有 $ \ln(1 - \alpha_i) \approx -\alpha_i - \frac{\alpha_i^2}{2} - \cdots \le -\alpha_i $</p><p>所以：</p><blockquote><p>$$
\ln P_n \le - \sum_{i=1}^n \alpha_i
\Rightarrow P_n \le \exp\left( -\sum_{i=1}^n \alpha_i \right)
$$</p></blockquote><p>因此：</p><ul><li>若 $ \sum \alpha_i = \infty $ → $ \ln P_n \to -\infty $ → $ P_n \to 0 $</li><li>若 $ \sum \alpha_i &lt; \infty $ → $ \ln P_n $ 收敛 → $ P_n $ 收敛到某个正数</li></ul><p>回到 Qₙ 的极限</p><p>因此：</p><table><thead><tr><th>条件</th><th>$ \sum \alpha_n $</th><th>$ C = \lim \prod (1-\alpha_i) $</th><th>$ Q_\infty $</th><th>是否收敛到 q*</th></tr></thead><tbody><tr><td>步长和有限</td><td>&lt; $\infty$</td><td>> 0</td><td>$ C Q_1 + (1 - C) q^* $</td><td>❌ 否</td></tr><tr><td>步长和无限</td><td>= ∞</td><td>= 0</td><td>$ q^* $</td><td>✅ 是</td></tr></tbody></table><blockquote><p>上述公式推导借助于AI,(AI)写公式真的快啊，省了很多时间</p></blockquote><h2 id=二k臂赌博机的增量实现以及k臂赌博机非平稳问题的实验>二：K臂赌博机的增量实现以及K臂赌博机非平稳问题的实验
<a class=header-anchor href=#%e4%ba%8ck%e8%87%82%e8%b5%8c%e5%8d%9a%e6%9c%ba%e7%9a%84%e5%a2%9e%e9%87%8f%e5%ae%9e%e7%8e%b0%e4%bb%a5%e5%8f%8ak%e8%87%82%e8%b5%8c%e5%8d%9a%e6%9c%ba%e9%9d%9e%e5%b9%b3%e7%a8%b3%e9%97%ae%e9%a2%98%e7%9a%84%e5%ae%9e%e9%aa%8c></a></h2><blockquote><p>写道这里注意到上次写的K臂赌博机用的就是标准增量公式，因此下面只给出K臂赌博机非平稳问题的实验</p></blockquote><h3 id=关于k臂赌博机的非平稳性问题>关于k臂赌博机的非平稳性问题
<a class=header-anchor href=#%e5%85%b3%e4%ba%8ek%e8%87%82%e8%b5%8c%e5%8d%9a%e6%9c%ba%e7%9a%84%e9%9d%9e%e5%b9%b3%e7%a8%b3%e6%80%a7%e9%97%ae%e9%a2%98></a></h3><blockquote><p>什么是非平稳性？</p></blockquote><blockquote><p>对于k臂赌博机，每个拉杆的期望不变就是平稳性，而每个拉杆的期望随着时间的变化改变了，就是非平稳性</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1>  1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2>  2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3>  3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4>  4</a>
</span><span class=lnt id=hl-0-5><a class=lnlinks href=#hl-0-5>  5</a>
</span><span class=lnt id=hl-0-6><a class=lnlinks href=#hl-0-6>  6</a>
</span><span class=lnt id=hl-0-7><a class=lnlinks href=#hl-0-7>  7</a>
</span><span class=lnt id=hl-0-8><a class=lnlinks href=#hl-0-8>  8</a>
</span><span class=lnt id=hl-0-9><a class=lnlinks href=#hl-0-9>  9</a>
</span><span class=lnt id=hl-0-10><a class=lnlinks href=#hl-0-10> 10</a>
</span><span class=lnt id=hl-0-11><a class=lnlinks href=#hl-0-11> 11</a>
</span><span class=lnt id=hl-0-12><a class=lnlinks href=#hl-0-12> 12</a>
</span><span class=lnt id=hl-0-13><a class=lnlinks href=#hl-0-13> 13</a>
</span><span class=lnt id=hl-0-14><a class=lnlinks href=#hl-0-14> 14</a>
</span><span class=lnt id=hl-0-15><a class=lnlinks href=#hl-0-15> 15</a>
</span><span class=lnt id=hl-0-16><a class=lnlinks href=#hl-0-16> 16</a>
</span><span class=lnt id=hl-0-17><a class=lnlinks href=#hl-0-17> 17</a>
</span><span class=lnt id=hl-0-18><a class=lnlinks href=#hl-0-18> 18</a>
</span><span class=lnt id=hl-0-19><a class=lnlinks href=#hl-0-19> 19</a>
</span><span class=lnt id=hl-0-20><a class=lnlinks href=#hl-0-20> 20</a>
</span><span class=lnt id=hl-0-21><a class=lnlinks href=#hl-0-21> 21</a>
</span><span class=lnt id=hl-0-22><a class=lnlinks href=#hl-0-22> 22</a>
</span><span class=lnt id=hl-0-23><a class=lnlinks href=#hl-0-23> 23</a>
</span><span class=lnt id=hl-0-24><a class=lnlinks href=#hl-0-24> 24</a>
</span><span class=lnt id=hl-0-25><a class=lnlinks href=#hl-0-25> 25</a>
</span><span class=lnt id=hl-0-26><a class=lnlinks href=#hl-0-26> 26</a>
</span><span class=lnt id=hl-0-27><a class=lnlinks href=#hl-0-27> 27</a>
</span><span class=lnt id=hl-0-28><a class=lnlinks href=#hl-0-28> 28</a>
</span><span class=lnt id=hl-0-29><a class=lnlinks href=#hl-0-29> 29</a>
</span><span class=lnt id=hl-0-30><a class=lnlinks href=#hl-0-30> 30</a>
</span><span class=lnt id=hl-0-31><a class=lnlinks href=#hl-0-31> 31</a>
</span><span class=lnt id=hl-0-32><a class=lnlinks href=#hl-0-32> 32</a>
</span><span class=lnt id=hl-0-33><a class=lnlinks href=#hl-0-33> 33</a>
</span><span class=lnt id=hl-0-34><a class=lnlinks href=#hl-0-34> 34</a>
</span><span class=lnt id=hl-0-35><a class=lnlinks href=#hl-0-35> 35</a>
</span><span class=lnt id=hl-0-36><a class=lnlinks href=#hl-0-36> 36</a>
</span><span class=lnt id=hl-0-37><a class=lnlinks href=#hl-0-37> 37</a>
</span><span class=lnt id=hl-0-38><a class=lnlinks href=#hl-0-38> 38</a>
</span><span class=lnt id=hl-0-39><a class=lnlinks href=#hl-0-39> 39</a>
</span><span class=lnt id=hl-0-40><a class=lnlinks href=#hl-0-40> 40</a>
</span><span class=lnt id=hl-0-41><a class=lnlinks href=#hl-0-41> 41</a>
</span><span class=lnt id=hl-0-42><a class=lnlinks href=#hl-0-42> 42</a>
</span><span class=lnt id=hl-0-43><a class=lnlinks href=#hl-0-43> 43</a>
</span><span class=lnt id=hl-0-44><a class=lnlinks href=#hl-0-44> 44</a>
</span><span class=lnt id=hl-0-45><a class=lnlinks href=#hl-0-45> 45</a>
</span><span class=lnt id=hl-0-46><a class=lnlinks href=#hl-0-46> 46</a>
</span><span class=lnt id=hl-0-47><a class=lnlinks href=#hl-0-47> 47</a>
</span><span class=lnt id=hl-0-48><a class=lnlinks href=#hl-0-48> 48</a>
</span><span class=lnt id=hl-0-49><a class=lnlinks href=#hl-0-49> 49</a>
</span><span class=lnt id=hl-0-50><a class=lnlinks href=#hl-0-50> 50</a>
</span><span class=lnt id=hl-0-51><a class=lnlinks href=#hl-0-51> 51</a>
</span><span class=lnt id=hl-0-52><a class=lnlinks href=#hl-0-52> 52</a>
</span><span class=lnt id=hl-0-53><a class=lnlinks href=#hl-0-53> 53</a>
</span><span class=lnt id=hl-0-54><a class=lnlinks href=#hl-0-54> 54</a>
</span><span class=lnt id=hl-0-55><a class=lnlinks href=#hl-0-55> 55</a>
</span><span class=lnt id=hl-0-56><a class=lnlinks href=#hl-0-56> 56</a>
</span><span class=lnt id=hl-0-57><a class=lnlinks href=#hl-0-57> 57</a>
</span><span class=lnt id=hl-0-58><a class=lnlinks href=#hl-0-58> 58</a>
</span><span class=lnt id=hl-0-59><a class=lnlinks href=#hl-0-59> 59</a>
</span><span class=lnt id=hl-0-60><a class=lnlinks href=#hl-0-60> 60</a>
</span><span class=lnt id=hl-0-61><a class=lnlinks href=#hl-0-61> 61</a>
</span><span class=lnt id=hl-0-62><a class=lnlinks href=#hl-0-62> 62</a>
</span><span class=lnt id=hl-0-63><a class=lnlinks href=#hl-0-63> 63</a>
</span><span class=lnt id=hl-0-64><a class=lnlinks href=#hl-0-64> 64</a>
</span><span class=lnt id=hl-0-65><a class=lnlinks href=#hl-0-65> 65</a>
</span><span class=lnt id=hl-0-66><a class=lnlinks href=#hl-0-66> 66</a>
</span><span class=lnt id=hl-0-67><a class=lnlinks href=#hl-0-67> 67</a>
</span><span class=lnt id=hl-0-68><a class=lnlinks href=#hl-0-68> 68</a>
</span><span class=lnt id=hl-0-69><a class=lnlinks href=#hl-0-69> 69</a>
</span><span class=lnt id=hl-0-70><a class=lnlinks href=#hl-0-70> 70</a>
</span><span class=lnt id=hl-0-71><a class=lnlinks href=#hl-0-71> 71</a>
</span><span class=lnt id=hl-0-72><a class=lnlinks href=#hl-0-72> 72</a>
</span><span class=lnt id=hl-0-73><a class=lnlinks href=#hl-0-73> 73</a>
</span><span class=lnt id=hl-0-74><a class=lnlinks href=#hl-0-74> 74</a>
</span><span class=lnt id=hl-0-75><a class=lnlinks href=#hl-0-75> 75</a>
</span><span class=lnt id=hl-0-76><a class=lnlinks href=#hl-0-76> 76</a>
</span><span class=lnt id=hl-0-77><a class=lnlinks href=#hl-0-77> 77</a>
</span><span class=lnt id=hl-0-78><a class=lnlinks href=#hl-0-78> 78</a>
</span><span class=lnt id=hl-0-79><a class=lnlinks href=#hl-0-79> 79</a>
</span><span class=lnt id=hl-0-80><a class=lnlinks href=#hl-0-80> 80</a>
</span><span class=lnt id=hl-0-81><a class=lnlinks href=#hl-0-81> 81</a>
</span><span class=lnt id=hl-0-82><a class=lnlinks href=#hl-0-82> 82</a>
</span><span class=lnt id=hl-0-83><a class=lnlinks href=#hl-0-83> 83</a>
</span><span class=lnt id=hl-0-84><a class=lnlinks href=#hl-0-84> 84</a>
</span><span class=lnt id=hl-0-85><a class=lnlinks href=#hl-0-85> 85</a>
</span><span class=lnt id=hl-0-86><a class=lnlinks href=#hl-0-86> 86</a>
</span><span class=lnt id=hl-0-87><a class=lnlinks href=#hl-0-87> 87</a>
</span><span class=lnt id=hl-0-88><a class=lnlinks href=#hl-0-88> 88</a>
</span><span class=lnt id=hl-0-89><a class=lnlinks href=#hl-0-89> 89</a>
</span><span class=lnt id=hl-0-90><a class=lnlinks href=#hl-0-90> 90</a>
</span><span class=lnt id=hl-0-91><a class=lnlinks href=#hl-0-91> 91</a>
</span><span class=lnt id=hl-0-92><a class=lnlinks href=#hl-0-92> 92</a>
</span><span class=lnt id=hl-0-93><a class=lnlinks href=#hl-0-93> 93</a>
</span><span class=lnt id=hl-0-94><a class=lnlinks href=#hl-0-94> 94</a>
</span><span class=lnt id=hl-0-95><a class=lnlinks href=#hl-0-95> 95</a>
</span><span class=lnt id=hl-0-96><a class=lnlinks href=#hl-0-96> 96</a>
</span><span class=lnt id=hl-0-97><a class=lnlinks href=#hl-0-97> 97</a>
</span><span class=lnt id=hl-0-98><a class=lnlinks href=#hl-0-98> 98</a>
</span><span class=lnt id=hl-0-99><a class=lnlinks href=#hl-0-99> 99</a>
</span><span class=lnt id=hl-0-100><a class=lnlinks href=#hl-0-100>100</a>
</span><span class=lnt id=hl-0-101><a class=lnlinks href=#hl-0-101>101</a>
</span><span class=lnt id=hl-0-102><a class=lnlinks href=#hl-0-102>102</a>
</span><span class=lnt id=hl-0-103><a class=lnlinks href=#hl-0-103>103</a>
</span><span class=lnt id=hl-0-104><a class=lnlinks href=#hl-0-104>104</a>
</span><span class=lnt id=hl-0-105><a class=lnlinks href=#hl-0-105>105</a>
</span><span class=lnt id=hl-0-106><a class=lnlinks href=#hl-0-106>106</a>
</span><span class=lnt id=hl-0-107><a class=lnlinks href=#hl-0-107>107</a>
</span><span class=lnt id=hl-0-108><a class=lnlinks href=#hl-0-108>108</a>
</span><span class=lnt id=hl-0-109><a class=lnlinks href=#hl-0-109>109</a>
</span><span class=lnt id=hl-0-110><a class=lnlinks href=#hl-0-110>110</a>
</span><span class=lnt id=hl-0-111><a class=lnlinks href=#hl-0-111>111</a>
</span><span class=lnt id=hl-0-112><a class=lnlinks href=#hl-0-112>112</a>
</span><span class=lnt id=hl-0-113><a class=lnlinks href=#hl-0-113>113</a>
</span><span class=lnt id=hl-0-114><a class=lnlinks href=#hl-0-114>114</a>
</span><span class=lnt id=hl-0-115><a class=lnlinks href=#hl-0-115>115</a>
</span><span class=lnt id=hl-0-116><a class=lnlinks href=#hl-0-116>116</a>
</span><span class=lnt id=hl-0-117><a class=lnlinks href=#hl-0-117>117</a>
</span><span class=lnt id=hl-0-118><a class=lnlinks href=#hl-0-118>118</a>
</span><span class=lnt id=hl-0-119><a class=lnlinks href=#hl-0-119>119</a>
</span><span class=lnt id=hl-0-120><a class=lnlinks href=#hl-0-120>120</a>
</span><span class=lnt id=hl-0-121><a class=lnlinks href=#hl-0-121>121</a>
</span><span class=lnt id=hl-0-122><a class=lnlinks href=#hl-0-122>122</a>
</span><span class=lnt id=hl-0-123><a class=lnlinks href=#hl-0-123>123</a>
</span><span class=lnt id=hl-0-124><a class=lnlinks href=#hl-0-124>124</a>
</span><span class=lnt id=hl-0-125><a class=lnlinks href=#hl-0-125>125</a>
</span><span class=lnt id=hl-0-126><a class=lnlinks href=#hl-0-126>126</a>
</span><span class=lnt id=hl-0-127><a class=lnlinks href=#hl-0-127>127</a>
</span><span class=lnt id=hl-0-128><a class=lnlinks href=#hl-0-128>128</a>
</span><span class=lnt id=hl-0-129><a class=lnlinks href=#hl-0-129>129</a>
</span><span class=lnt id=hl-0-130><a class=lnlinks href=#hl-0-130>130</a>
</span><span class=lnt id=hl-0-131><a class=lnlinks href=#hl-0-131>131</a>
</span><span class=lnt id=hl-0-132><a class=lnlinks href=#hl-0-132>132</a>
</span><span class=lnt id=hl-0-133><a class=lnlinks href=#hl-0-133>133</a>
</span><span class=lnt id=hl-0-134><a class=lnlinks href=#hl-0-134>134</a>
</span><span class=lnt id=hl-0-135><a class=lnlinks href=#hl-0-135>135</a>
</span><span class=lnt id=hl-0-136><a class=lnlinks href=#hl-0-136>136</a>
</span><span class=lnt id=hl-0-137><a class=lnlinks href=#hl-0-137>137</a>
</span><span class=lnt id=hl-0-138><a class=lnlinks href=#hl-0-138>138</a>
</span><span class=lnt id=hl-0-139><a class=lnlinks href=#hl-0-139>139</a>
</span><span class=lnt id=hl-0-140><a class=lnlinks href=#hl-0-140>140</a>
</span><span class=lnt id=hl-0-141><a class=lnlinks href=#hl-0-141>141</a>
</span><span class=lnt id=hl-0-142><a class=lnlinks href=#hl-0-142>142</a>
</span><span class=lnt id=hl-0-143><a class=lnlinks href=#hl-0-143>143</a>
</span><span class=lnt id=hl-0-144><a class=lnlinks href=#hl-0-144>144</a>
</span><span class=lnt id=hl-0-145><a class=lnlinks href=#hl-0-145>145</a>
</span><span class=lnt id=hl-0-146><a class=lnlinks href=#hl-0-146>146</a>
</span><span class=lnt id=hl-0-147><a class=lnlinks href=#hl-0-147>147</a>
</span><span class=lnt id=hl-0-148><a class=lnlinks href=#hl-0-148>148</a>
</span><span class=lnt id=hl-0-149><a class=lnlinks href=#hl-0-149>149</a>
</span><span class=lnt id=hl-0-150><a class=lnlinks href=#hl-0-150>150</a>
</span><span class=lnt id=hl-0-151><a class=lnlinks href=#hl-0-151>151</a>
</span><span class=lnt id=hl-0-152><a class=lnlinks href=#hl-0-152>152</a>
</span><span class=lnt id=hl-0-153><a class=lnlinks href=#hl-0-153>153</a>
</span><span class=lnt id=hl-0-154><a class=lnlinks href=#hl-0-154>154</a>
</span><span class=lnt id=hl-0-155><a class=lnlinks href=#hl-0-155>155</a>
</span><span class=lnt id=hl-0-156><a class=lnlinks href=#hl-0-156>156</a>
</span><span class=lnt id=hl-0-157><a class=lnlinks href=#hl-0-157>157</a>
</span><span class=lnt id=hl-0-158><a class=lnlinks href=#hl-0-158>158</a>
</span><span class=lnt id=hl-0-159><a class=lnlinks href=#hl-0-159>159</a>
</span><span class=lnt id=hl-0-160><a class=lnlinks href=#hl-0-160>160</a>
</span><span class=lnt id=hl-0-161><a class=lnlinks href=#hl-0-161>161</a>
</span><span class=lnt id=hl-0-162><a class=lnlinks href=#hl-0-162>162</a>
</span><span class=lnt id=hl-0-163><a class=lnlinks href=#hl-0-163>163</a>
</span><span class=lnt id=hl-0-164><a class=lnlinks href=#hl-0-164>164</a>
</span><span class=lnt id=hl-0-165><a class=lnlinks href=#hl-0-165>165</a>
</span><span class=lnt id=hl-0-166><a class=lnlinks href=#hl-0-166>166</a>
</span><span class=lnt id=hl-0-167><a class=lnlinks href=#hl-0-167>167</a>
</span><span class=lnt id=hl-0-168><a class=lnlinks href=#hl-0-168>168</a>
</span><span class=lnt id=hl-0-169><a class=lnlinks href=#hl-0-169>169</a>
</span><span class=lnt id=hl-0-170><a class=lnlinks href=#hl-0-170>170</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#设置中文字体与美化样式</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s2>&#34;font.sans-serif&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;SimHei&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s2>&#34;axes.unicode_minus&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>style</span><span class=o>=</span><span class=s2>&#34;whitegrid&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#定义赌博机环境</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>KArmedBandit</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span> <span class=n>seed</span> <span class=o>=</span> <span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        初始化k臂赌博机
</span></span></span><span class=line><span class=cl><span class=s2>        K: 动作数量
</span></span></span><span class=line><span class=cl><span class=s2>        seed: 随机种子，使实验可复现
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=n>k</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>seed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q_star</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_action</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>q_star</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_q_star</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_star</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>action</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        执行动作，返回奖励
</span></span></span><span class=line><span class=cl><span class=s2>        奖励 ~ N(q_star[action],1)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 每走一步，对期望添加均值为0且标准差为0.01的正态分布增量</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q_star</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>k</span><span class=p>)</span><span class=o>*</span><span class=mf>0.01</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>()</span><span class=o>+</span><span class=bp>self</span><span class=o>.</span><span class=n>q_star</span><span class=p>[</span><span class=n>action</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义 ε-贪婪智能体</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>EpsilonGreedyAgent</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>k</span><span class=p>,</span> <span class=n>epsilon</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        k: 动作数量
</span></span></span><span class=line><span class=cl><span class=s2>        epsilon: 探索概率
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=n>k</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>epsilon</span> <span class=o>=</span> <span class=n>epsilon</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>seed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>Q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>k</span><span class=p>)</span>    <span class=c1># 定义奖励函数</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>N</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>k</span><span class=p>)</span>    <span class=c1># 保存每个动作被选择的次数，方便计算状态奖励</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>select_action</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        动作选择
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span><span class=o>&lt;</span><span class=bp>self</span><span class=o>.</span><span class=n>epsilon</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># exploration 探索，选择随机动作</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># exploitation</span>
</span></span><span class=line><span class=cl>            <span class=n>max_Q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>Q</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>best_actions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>Q</span><span class=o>==</span><span class=n>max_Q</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>  <span class=c1>#where函数返回满足条件的位置索引</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>best_actions</span><span class=p>)</span>   <span class=c1>#当有多个最大奖励时，随机返回一个，这里也认为是一次贪婪行为 </span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>action</span><span class=p>,</span><span class=n>reward</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        更新
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>N</span><span class=p>[</span><span class=n>action</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=c1>## 修改此处的更新为常量增量更新</span>
</span></span><span class=line><span class=cl>        <span class=c1>## self.Q[action] += (reward-self.Q[action])/self.N[action]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>Q</span><span class=p>[</span><span class=n>action</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>Q</span><span class=p>[</span><span class=n>action</span><span class=p>]</span> <span class=o>+</span> <span class=mf>0.1</span><span class=o>*</span><span class=p>(</span><span class=n>reward</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>Q</span><span class=p>[</span><span class=n>action</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 运行单次实验</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_expriment</span><span class=p>(</span><span class=n>bandit</span><span class=p>,</span> <span class=n>agent</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    运行一次实验
</span></span></span><span class=line><span class=cl><span class=s2>    返回: 每一步的奖励，是否选择了最优动作
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>rewards</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>is_best_actions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>steps</span><span class=p>,</span><span class=n>dtype</span><span class=o>=</span><span class=nb>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>action</span> <span class=o>=</span> <span class=n>agent</span><span class=o>.</span><span class=n>select_action</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>reward</span> <span class=o>=</span> <span class=n>bandit</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>agent</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>action</span><span class=p>,</span><span class=n>reward</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span><span class=p>[</span><span class=n>t</span><span class=p>]</span> <span class=o>=</span> <span class=n>reward</span>
</span></span><span class=line><span class=cl>        <span class=n>is_best_actions</span><span class=p>[</span><span class=n>t</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>action</span> <span class=o>==</span> <span class=n>bandit</span><span class=o>.</span><span class=n>best_action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>rewards</span><span class=p>,</span> <span class=n>is_best_actions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 主实验</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main_expriment</span><span class=p>(</span><span class=n>epsilons</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mf>0.01</span><span class=p>,</span><span class=mf>0.1</span><span class=p>],</span> <span class=n>runs</span> <span class=o>=</span> <span class=mi>2000</span><span class=p>,</span> <span class=n>steps</span> <span class=o>=</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span> <span class=n>seed</span> <span class=o>=</span> <span class=mi>42</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    对每一个epsilon，运行runs次实验，每次steps步。
</span></span></span><span class=line><span class=cl><span class=s2>    return: 平均奖励矩阵, 最优动作选择矩阵
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>average_rewards</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>epsilons</span><span class=p>),</span><span class=n>steps</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>average_best_actions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>epsilons</span><span class=p>),</span><span class=n>steps</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span><span class=n>epsilon</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>epsilons</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;running expriments for E = </span><span class=si>{</span><span class=n>epsilon</span><span class=si>}</span><span class=s2>...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>total_rewards</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>total_best_actions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>run</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>runs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>            为每次运行创建新的赌博机
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>            <span class=n>bandit</span> <span class=o>=</span> <span class=n>KArmedBandit</span><span class=p>(</span><span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>seed</span> <span class=o>+</span><span class=n>run</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>agent</span> <span class=o>=</span> <span class=n>EpsilonGreedyAgent</span><span class=p>(</span><span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=n>epsilon</span><span class=p>,</span> <span class=n>seed</span> <span class=o>=</span> <span class=n>seed</span><span class=o>+</span><span class=n>run</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># print(bandit.get_q_star())</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span><span class=p>,</span> <span class=n>is_best</span> <span class=o>=</span> <span class=n>run_expriment</span><span class=p>(</span><span class=n>bandit</span><span class=p>,</span><span class=n>agent</span><span class=p>,</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>total_rewards</span> <span class=o>+=</span> <span class=n>rewards</span>
</span></span><span class=line><span class=cl>            <span class=n>total_best_actions</span> <span class=o>+=</span> <span class=n>is_best</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>average_best_actions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>total_best_actions</span><span class=o>/</span><span class=n>runs</span>
</span></span><span class=line><span class=cl>        <span class=n>average_rewards</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>total_rewards</span><span class=o>/</span><span class=n>runs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>average_rewards</span><span class=p>,</span> <span class=n>average_best_actions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>plot_results</span><span class=p>(</span><span class=n>avg_rewards</span><span class=p>,</span> <span class=n>avg_best_action_rates</span><span class=p>,</span> <span class=n>epsilons</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 平均奖励</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>epsilon</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>epsilons</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>steps</span> <span class=o>+</span> <span class=mi>1</span><span class=p>),</span> <span class=n>avg_rewards</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;ε = </span><span class=si>{</span><span class=n>epsilon</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Steps&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Average Reward&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Average Reward over Time&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 最优动作选择率</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>epsilon</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>epsilons</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>steps</span> <span class=o>+</span> <span class=mi>1</span><span class=p>),</span> <span class=n>avg_best_action_rates</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;ε = </span><span class=si>{</span><span class=n>epsilon</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Steps&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;% Optimal Action&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Optimal Action Selection Rate over Time&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 设置参数</span>
</span></span><span class=line><span class=cl>    <span class=n>EPSILONS</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>RUNS</span> <span class=o>=</span> <span class=mi>2000</span>
</span></span><span class=line><span class=cl>    <span class=n>STEPS</span> <span class=o>=</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 运行实验</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_rewards</span><span class=p>,</span> <span class=n>avg_best_action_rates</span> <span class=o>=</span> <span class=n>main_expriment</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>epsilons</span><span class=o>=</span><span class=n>EPSILONS</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>runs</span><span class=o>=</span><span class=n>RUNS</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>steps</span><span class=o>=</span><span class=n>STEPS</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>seed</span><span class=o>=</span><span class=mi>42</span>  <span class=c1># 为了复现性，你可以改变或移除</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>avg_rewards</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span><span class=n>avg_best_action_rates</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(avg_best_action_rates,avg_rewards)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 绘图</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_results</span><span class=p>(</span><span class=n>avg_rewards</span><span class=p>,</span> <span class=n>avg_best_action_rates</span><span class=p>,</span> <span class=n>EPSILONS</span><span class=p>,</span> <span class=n>STEPS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 打印长期（最后100步）平均表现</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>=== 长期表现（最后100步平均） ===&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>eps</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>EPSILONS</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>last_100_reward</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>avg_rewards</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=o>-</span><span class=mi>100</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>        <span class=n>last_100_optimal</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>avg_best_action_rates</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=o>-</span><span class=mi>100</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ε = </span><span class=si>{</span><span class=n>eps</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>: 平均奖励 = </span><span class=si>{</span><span class=n>last_100_reward</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, 最优动作率 = </span><span class=si>{</span><span class=n>last_100_optimal</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><h3 id=结果>结果
<a class=header-anchor href=#%e7%bb%93%e6%9e%9c></a></h3><p><img src=/imgs/img-lazy-loading.gif data-src=/images/k%e8%87%82%e8%b5%8c%e5%8d%9a%e6%9c%ba%e7%bb%93%e6%9e%9c/%e9%9d%9e%e5%b9%b3%e7%a8%b3%e9%97%ae%e9%a2%98%e7%9a%84%e5%9b%b0%e9%9a%be%e6%80%a7.png alt></p><p>=== 长期表现（最后100步平均） ===</p><p>ε = 0.00: 平均奖励 = 1.306, 最优动作率 = 0.546</p><p>ε = 0.01: 平均奖励 = 1.361, 最优动作率 = 0.571</p><p>ε = 0.10: 平均奖励 = 1.397, 最优动作率 = 0.669</p></div><footer class=post-footer><hr><div class=post-copyright><img src=/imgs/cc/cc.svg class=cc-icon width=75 height=75 align=right alt="Creative Commons" title="Creative Commons"><ul><li class=post-copyright-title><strong>Post Title:</strong>
K臂赌博机的增量实现以及追踪非平衡问题</li><li class=post-copyright-author><strong>Post Author: </strong>惜日短</li><li class=post-copyright-link><strong>Post Link:</strong>
<a id=post-cr-link href=https://hwsirz.github.io/reinforcement-learning/k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/ title=K臂赌博机的增量实现以及追踪非平衡问题>https://hwsirz.github.io/reinforcement-learning/k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/</a></li><li class=post-copyright-license><strong>Copyright Notice: </strong>This work is licensed under <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en>BY-NC-SA</a> .</li><li><div class=license-icons><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en target=_blank><img src=/imgs/cc/big/by_nc_sa.svg alt=BY-NC-SA title=BY-NC-SA>
</a><a href=https://notbyai.fyi target=_blank><img src=/imgs/notbyai/en/white.svg title="Not By AI"></a></div></li></ul></div><div class=followme><span>Welcome to my other publishing channels</span><div class=social-list><div class=social-item><a target=_blank class=social-link href><span class=icon><i></i>
</span><span class=label></span></a></div><div class=social-item><a target=_blank class=social-link href><span class=icon><i></i>
</span><span class=label></span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/reinforcement-learning/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/ rel=next title=蒙特卡洛方法><i class="fa fa-chevron-left"></i> 蒙特卡洛方法</a></div><div class="post-nav-prev post-nav-item"><a href=/reinforcement-learning/k%E8%87%82%E5%B9%B3%E7%A8%B3%E8%B5%8C%E5%8D%9A%E6%9C%BA/ rel=prev title=K臂平稳赌博机>K臂平稳赌博机
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2025
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>惜日短</span></div></div></footer><script class=next-config data-name=page type=application/json>{"clipboard":{"js":{"alias":"clipboard","file":"dist/clipboard.min.js","name":"clipboard.js","version":"2.0.11"}},"comments":false,"expired":false,"isHome":false,"isPage":true,"math":{"js":{"file":"es5/tex-mml-svg.js","name":"mathjax","version":"3.2.2"},"render":"mathjax"},"path":"k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98","permalink":"https://hwsirz.github.io/reinforcement-learning/k%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA%E7%9A%84%E5%A2%9E%E9%87%8F%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E8%BF%BD%E8%B8%AA%E9%9D%9E%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98/","title":"K臂赌博机的增量实现以及追踪非平衡问题","toc":true}</script><script type=text/javascript src=https://hwsirz.github.io/js/3rd/animejs/3.2.2/anime.min.js crossorigin=anonymous defer></script><script type=text/javascript src=https://hwsirz.github.io/js/3rd/viewerjs/1.11.6/viewer.min.js crossorigin=anonymous defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":true,"save":"manual"},"copybtn":true,"darkmode":true,"hostname":"https://hwsirz.github.io/","i18n":{"ds_day":" Day Ago","ds_days":" Day ","ds_hour":" Hour Ago","ds_hours":" Hour ","ds_just":"Just","ds_min":" Min Ago","ds_mins":" Min","ds_month":" Month Ago","ds_years":" Year ","empty":"We didn't find any results for the search: ${query}","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms","placeholder":"Searching..."},"isMultiLang":false,"lang":"en-US","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"slideInRight","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":false,"plugin":"waline"},"views":{"enable":false,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","share":{"addtoany":{"js":"https://static.addtoany.com/menu/page.js","locale":"zh-CN","num":8},"enable":false},"sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"local","router":{"name":"local","type":"modern","url":"https://hwsirz.github.io/js/3rd"}},"version":"4.8.3","waline":{"cfg":{"emoji":false,"imguploader":false,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"@waline/client","file":"dist/waline.css","name":"waline","version":"2.15.8"},"js":{"alias":"@waline/client","file":"dist/waline.js","name":"waline","version":"2.15.8"}}}</script><script type=text/javascript src="/js/main.min.js?=1761104601" defer></script><script type=text/javascript src="/js/clipboard.min.js?=1761104602" defer></script><script type=text/javascript src="/js/math.min.js?=1761104602" defer></script></body></html>